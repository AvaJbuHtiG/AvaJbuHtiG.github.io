<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>hadoop之mapReduce | zgq's blog</title><meta name="description" content="hadoop之mapReduce"><meta name="keywords" content="大数据  hadoop MapReduce"><meta name="author" content="zgq"><meta name="copyright" content="zgq"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="hadoop之mapReduce"><meta name="twitter:description" content="hadoop之mapReduce"><meta name="twitter:image" content="https://avajbuhtig.github.io/img/post.jpg"><meta property="og:type" content="article"><meta property="og:title" content="hadoop之mapReduce"><meta property="og:url" content="https://avajbuhtig.github.io/2020/01/01/hadoop%E4%B9%8BmapReduce/"><meta property="og:site_name" content="zgq's blog"><meta property="og:description" content="hadoop之mapReduce"><meta property="og:image" content="https://avajbuhtig.github.io/img/post.jpg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://avajbuhtig.github.io/2020/01/01/hadoop%E4%B9%8BmapReduce/"><link rel="prev" title="zookeeper基础" href="https://avajbuhtig.github.io/2020/01/22/zookeeper/"><link rel="next" title="hadoop之基础集群搭建" href="https://avajbuhtig.github.io/2020/01/01/hadoop%E4%B9%8B%E5%9F%BA%E7%A1%80%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">24</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">13</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#核心编程思想"><span class="toc-number">1.</span> <span class="toc-text">核心编程思想</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce进程"><span class="toc-number">2.</span> <span class="toc-text">MapReduce进程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#常用数据类型"><span class="toc-number">3.</span> <span class="toc-text">常用数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义MapReduce程序"><span class="toc-number">4.</span> <span class="toc-text">自定义MapReduce程序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce序列化"><span class="toc-number">5.</span> <span class="toc-text">MapReduce序列化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#自定义对象的序列化方式"><span class="toc-number">5.0.1.</span> <span class="toc-text">自定义对象的序列化方式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce原理"><span class="toc-number">6.</span> <span class="toc-text">MapReduce原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#InputFormat"><span class="toc-number">6.1.</span> <span class="toc-text">InputFormat</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#TextInputFormat"><span class="toc-number">6.1.1.</span> <span class="toc-text">TextInputFormat:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KeyValueTextInputFormat："><span class="toc-number">6.1.2.</span> <span class="toc-text">KeyValueTextInputFormat：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NLineInputFormat"><span class="toc-number">6.1.3.</span> <span class="toc-text">NLineInputFormat:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CombineTextInputFormat"><span class="toc-number">6.1.4.</span> <span class="toc-text">CombineTextInputFormat:</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SequenceFileInputFormat："><span class="toc-number">6.1.5.</span> <span class="toc-text">SequenceFileInputFormat：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#自定义InputFormat"><span class="toc-number">6.2.</span> <span class="toc-text">自定义InputFormat</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#自定义分区"><span class="toc-number">6.3.</span> <span class="toc-text">自定义分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WritableComparable排序"><span class="toc-number">6.4.</span> <span class="toc-text">WritableComparable排序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#排序"><span class="toc-number">6.4.1.</span> <span class="toc-text">排序</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Combine合并"><span class="toc-number">6.5.</span> <span class="toc-text">Combine合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GroupingComparator分组-辅助分组"><span class="toc-number">6.6.</span> <span class="toc-text">GroupingComparator分组(辅助分组)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OutputFormat"><span class="toc-number">6.7.</span> <span class="toc-text">OutputFormat</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Join"><span class="toc-number">6.8.</span> <span class="toc-text">Join</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Reduce-join"><span class="toc-number">6.8.1.</span> <span class="toc-text">Reduce join</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#map-join"><span class="toc-number">6.8.2.</span> <span class="toc-text">map join</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据清洗"><span class="toc-number">6.9.</span> <span class="toc-text">数据清洗</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#工作原理"><span class="toc-number">6.10.</span> <span class="toc-text">工作原理</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(/img/post.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">zgq's blog</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">hadoop之mapReduce</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-01-01 17:57:50"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-01-01</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-04-22 10:23:14"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-04-22</span></time></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><p>MapReduce是一个分布式运算程序的编程框架，核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式计算程序，并发运行在hadoop集群上。</p>
<a id="more"></a>

<p>优点：易于编程，良好的扩展性，适合海量数据的计算，高容错性</p>
<p>高容错性表现在，一个计算任务在某一个节点运行失败，会把任务转移到其他节点上运行，不需要人工干预，自动完成的。</p>
<p>缺点：不擅长实施计算，不擅长流式计算，不擅长有向图(DAG)计算</p>
<h2 id="核心编程思想"><a href="#核心编程思想" class="headerlink" title="核心编程思想"></a>核心编程思想</h2><p><img src="/" class="lazyload" data-src="C:%5CUsers%5Czgq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1577885071607.png"  alt="1577885071607"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）分布式的运算程序往往需要分成至少2个阶段。</span><br><span class="line">2）第一个阶段的MapTask并发实例，完全并行运行，互不相干。</span><br><span class="line">3）第二个阶段的ReduceTask并发实例互不相干，但是他们的数据依赖于上一个阶段的所有MapTask并发实例的输出。</span><br><span class="line">4）MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序，串行运行。</span><br></pre></td></tr></table></figure>

<h2 id="MapReduce进程"><a href="#MapReduce进程" class="headerlink" title="MapReduce进程"></a>MapReduce进程</h2><p>在完成一个完整的MapReduce分布式任务中，会有以下三类示例进程</p>
<p>1、MrAppMaster：负责整个程序的调度以及状态协调</p>
<p>2、MapTask：负责Map阶段的整个数据处理流程</p>
<p>3、ReduceTask：负责Reduce阶段的整个数据处理流程</p>
<p>通常来说，用户编写MapReduce程序，需要开发三个部分，Mapper，Reducer， Driver</p>
<h2 id="常用数据类型"><a href="#常用数据类型" class="headerlink" title="常用数据类型"></a>常用数据类型</h2><p>在hadoop中，数据类型不能用Java的，对应的关系如下</p>
<table>
<thead>
<tr>
<th>Java类型</th>
<th><strong>Hadoop Writable类型</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Boolean</td>
<td>BooleanWritable</td>
</tr>
<tr>
<td>Byte</td>
<td>ByteWritable</td>
</tr>
<tr>
<td>Int</td>
<td>IntWritable</td>
</tr>
<tr>
<td>Float</td>
<td>FloatWritable</td>
</tr>
<tr>
<td>Long</td>
<td>LongWritable</td>
</tr>
<tr>
<td>Double</td>
<td>DoubleWritable</td>
</tr>
<tr>
<td>String</td>
<td>Text</td>
</tr>
<tr>
<td>Map</td>
<td>MapWritable</td>
</tr>
<tr>
<td>Array</td>
<td>ArrayWritable</td>
</tr>
</tbody></table>
<h2 id="自定义MapReduce程序"><a href="#自定义MapReduce程序" class="headerlink" title="自定义MapReduce程序"></a>自定义MapReduce程序</h2><p>上面讲到，用户自定义MapReduce分布式任务程序时，有三个部分需要开发</p>
<p>Map任务，Reduce任务，Driver</p>
<p>下面的示例是官方的一个自定义wordCount，相当于hadoop中的“hello world”</p>
<p>Map任务开发：</p>
<p>1、继承Mapper类，有4个泛型，keyIn，valueIn，keyOut，valueOut,都可以自定义类型</p>
<p>2、业务逻辑写在map方法中</p>
<p>3、map方法(MapTask进程负责调用)会对每一个&lt;K,V&gt;调用一次</p>
<p>自定义的WordCount中，Map代码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 用户自定义的MapReduce的mapper需要继承Mapper类，该类有4个泛型</span></span><br><span class="line"><span class="comment"> * KeyIn 程序输入的数据的key，表示的是距离文本首行首个字的偏移量</span></span><br><span class="line"><span class="comment"> * ValueIn 对应偏移量的内容</span></span><br><span class="line"><span class="comment"> * KeyOut   任务结束时，输出的key类型，用户决定</span></span><br><span class="line"><span class="comment"> * ValueOut  任务结束时，输出的value，用户决定</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WcMapper</span>  <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line">    <span class="keyword">private</span> IntWritable count = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String line = value.toString();</span><br><span class="line"></span><br><span class="line">        String[] words = line.split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将分割出来的单词交给job的上下文 context是job的上下文</span></span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            <span class="keyword">this</span>.word.set(word);</span><br><span class="line">            context.write(<span class="keyword">this</span>.word, <span class="keyword">this</span>.count);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>reduce任务开发：</p>
<p>1、继承Reducer类，有4个泛型，keyIn，valueIn，keyOut，valueOut,根据mapper输出类型决定</p>
<p>2、业务逻辑任务写在reduceer方法中</p>
<p>3、ReducerTask进程会对每一株相同的&lt;K,V&gt;组调用一次reduce方法</p>
<p>Driver任务开发：</p>
<p>类似于jdbc驱动注册的，写起来基本一样，代码基本不变</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WcDriver</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// job实例</span></span><br><span class="line">        Job job = Job.getInstance(<span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置Driver类路径</span></span><br><span class="line">        job.setJarByClass(WcDriver<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置mapper和Reduce</span></span><br><span class="line">        job.setMapperClass(WcMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setReducerClass(WcReducer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置Mapper和Reduce的输出类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setMapOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置输入输出数据</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交job</span></span><br><span class="line">        <span class="keyword">boolean</span> b = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="MapReduce序列化"><a href="#MapReduce序列化" class="headerlink" title="MapReduce序列化"></a>MapReduce序列化</h2><p>hadoop中，数据反复在集群中交互，需要返回的序列化。虽然hadoop的继续java开发的，但是hadoop的序列化机制并没有使用java的序列化机制。而是开发了一套自己的序列化机制writable。Java序列化机制是很重量级的，对象序列化之后会附带很多额外信息，这些信息对于hadoop而言，没有作用。对于频繁的序列化与反序列化，用这种重量级的序列化机制，会暂用较大的IO资源，不适合hadoop。</p>
<p>hadoop序列化机制的特点：</p>
<p>紧凑，快速，可扩展，互操作(支持多语言交互)</p>
<h4 id="自定义对象的序列化方式"><a href="#自定义对象的序列化方式" class="headerlink" title="自定义对象的序列化方式"></a>自定义对象的序列化方式</h4><p>自定义bean的序列化只要实现Wirtable接口，实现write，readField方法。具体如下，要注意的是</p>
<p>反序列方法中数据写出顺序要和反序列化数据读入顺序保持一致，不然属性的值会乱，甚至抛异常</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@ToString</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlowBean</span> <span class="keyword">implements</span> <span class="title">Writable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Long upFlow;</span><br><span class="line">    <span class="keyword">private</span> Long downFlow;</span><br><span class="line">    <span class="keyword">private</span> Long sumFlow;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 序列化方法  序列方法中数据写出顺序要和反序列化数据读入顺序保持一致</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@author</span> GuoQiang.Zhou</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@date</span> 2020/1/2 22:16</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> dataOutput mapReduce提供的数据出口</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        dataOutput.writeLong(<span class="keyword">this</span>.upFlow);</span><br><span class="line">        dataOutput.writeLong(<span class="keyword">this</span>.downFlow);</span><br><span class="line">        dataOutput.writeLong(<span class="keyword">this</span>.sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 反序列化方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@author</span> GuoQiang.Zhou</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@date</span> 2020/1/2 22:16</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> dataInput</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.upFlow = dataInput.readLong();</span><br><span class="line">        <span class="keyword">this</span>.downFlow = dataInput.readLong();</span><br><span class="line">        <span class="keyword">this</span>.sumFlow = dataInput.readLong();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="MapReduce原理"><a href="#MapReduce原理" class="headerlink" title="MapReduce原理"></a>MapReduce原理</h2><p>mapreduce中，处理数据的流程如下</p>
<p><img src="/" class="lazyload" data-src="C:%5CUsers%5Czgq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1577976490272.png"  alt="1577976490272"></p>
<p>mapReduce作为一个分布式计算框架，必然会有任务的并行计算。并行计算就会涉及到任务的切分，根据数据的切分然后决定启动多少个MapTask来计算任务。那么这个任务的切分由谁来操作，又是如何切分的呢。</p>
<p>这个就要了解前面写Driver的时候用到的FileInputFormat对象了。任务的切分由FileInputFormat进行，任务默认是按快大小切分的，也可以自定义设置，但是不建议这么做。</p>
<p>假设一个任务的文件是300M，可知这个文件被分为3块，分布在3个节点上。</p>
<p>按照块大小切分：</p>
<p>任务被切成3份，第一份128M，第二份128M，第三份44M，节点1上的块1，正好是任务第一份的大小，在节点1上创建MapTask，并提交，依次类推，在节点2，3上的块正好是任务对应的文件大小，都在块所在的节点上创建MapTask，并提交。</p>
<p>不按块大小切分：</p>
<p>同样，务被切成3份，每份100M，但是节点1上，快大小为128M，有28M的数据需要住那一到另一个节点上，</p>
<p>节点2同样的情况，在节点1，2，分别需要传输28M的数据到节点3上。所以，不按照块大小切分，该任务会占用56M的IO，这样会导致集群资源紧张。</p>
<p>注意：这里提到的在某个块所在节点创建的MapTask会在本地提交，因为yarn有一个优化原则，尽量在本地提交Task，避免IO</p>
<h3 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h3><p>InputFormat除了会将前面讲到的把任务分片之外，还会把每个分片的文件数据变成K,V值的形式。把数据变成K，V值是有对应的RecordReader对象完成的。</p>
<p>MapReduce内部已经提供了一些官方定义的InputFormat。有TextInputFormat,KeyValueTextInputFormat,NLineInputFormat,CombineTextInputforMat。</p>
<h4 id="TextInputFormat"><a href="#TextInputFormat" class="headerlink" title="TextInputFormat:"></a>TextInputFormat:</h4><p>是默认的InputFormat，会按行读取每条记录，key是该行在文件中字节偏移量，LongWritable，value是行的内容，不含任何行终止符(换行和回车)， Text类型。</p>
<h4 id="KeyValueTextInputFormat："><a href="#KeyValueTextInputFormat：" class="headerlink" title="KeyValueTextInputFormat："></a>KeyValueTextInputFormat：</h4><p>按照设置的分隔符将每行数据分隔为前后2部分，前面部分为key，后面为value。默认是分隔符是/t。</p>
<h4 id="NLineInputFormat"><a href="#NLineInputFormat" class="headerlink" title="NLineInputFormat:"></a>NLineInputFormat:</h4><p>如果使用NLineInputFormat，不在按照Block大小切分任务，而是按照NLineInputFormat指定的行数切分，key是偏移量，value是某几行的数据。</p>
<h4 id="CombineTextInputFormat"><a href="#CombineTextInputFormat" class="headerlink" title="CombineTextInputFormat:"></a>CombineTextInputFormat:</h4><p>用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p>
<p>CombineTextInputFormat涉及到一个虚拟存储的过程。虚拟存储切片最大值是可以根据实际情况设置的。假设该值设置为4兆，切片机制如下</p>
<p><img src="/" class="lazyload" data-src="C:%5CUsers%5Czgq%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1578060623605.png"  alt="1578060623605"></p>
<h4 id="SequenceFileInputFormat："><a href="#SequenceFileInputFormat：" class="headerlink" title="SequenceFileInputFormat："></a>SequenceFileInputFormat：</h4><p>用于Task间数据有依赖的场景。例如：TaskA处理完的数据，要交给TaskB处理。如果将数据落盘，则会有两次IO，这时候就需要使用SequenceFileFormat了。TaskA是、处理完数据用SequenceFileOutputFormat数据结果，TaskB用SequenceFileInputFormat接收数据。</p>
<p>在这些InputFormat中，NLineInputFormat会改变每个map处理的分片数据大小，会按照指定的行数来将输入数据分片，TextInputFormat，KeyValueTextInputFormat都是按照block大小来将数据分片，只是会改变将每行数据变为KV值的规则。</p>
<p>各InputFormat切片方法和RecordReader对应</p>
<table>
<thead>
<tr>
<th align="center">InputFormat</th>
<th>切片方法</th>
<th>kv方法(RecordReader)</th>
</tr>
</thead>
<tbody><tr>
<td align="center">TextInputFormat</td>
<td>父类FileInputFormat的方法</td>
<td>LineRecordReader</td>
</tr>
<tr>
<td align="center">KeyValueTextInputFormat</td>
<td>父类FileInputFormat的方法</td>
<td>KeyValueLineRecordReader</td>
</tr>
<tr>
<td align="center">NLineInputFormat</td>
<td>自定义，N行一个KV值</td>
<td>LineRecordReader</td>
</tr>
<tr>
<td align="center">CombineTextInputFormat</td>
<td>自定义</td>
<td>CombieRecordReader</td>
</tr>
<tr>
<td align="center">SequenceFileInputFormat</td>
<td>自定义</td>
<td>SequenceFileRecordReader</td>
</tr>
</tbody></table>
<p>上面的几个InputFormat运用示例如下：</p>
<p>1、KeyValueTextInputFormat</p>
<p>mapper，reducer怎么写就不写了，主要记录下在job设置时的不同，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置KeyValueLineRecordReader的分隔符，默认是\t</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, <span class="string">" "</span>);</span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(InputFormatDriver<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(KeyValueTextInputFormatMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setReducerClass(KeyValueTextInputFormatReduce<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setMapOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        job.setOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 设置InputFormat class类</span></span><br><span class="line">        job.setInputFormatClass(KeyValueTextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(<span class="string">"F:\\Desktop\\hello.txt"</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"F:\\Desktop\\output"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">boolean</span> b = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        System.exit( b ? <span class="number">0</span> : <span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>这里指定的分隔符，会按照该分隔符在每行中第一次出现的位置切片。</p>
<p>2、NLineInputFormat。</p>
<p>mapper， reducer也不记录了，主要记录下Driver中job设置的不同，每两行作为一个切片</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf &#x3D; new Configuration();</span><br><span class="line">        Job job &#x3D; Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(InputFormatDriver.class);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(NLineInputFormatMapper.class);</span><br><span class="line">        job.setReducerClass(NLineInputFormatReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(LongWritable.class);</span><br><span class="line">        job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line">        &#x2F;&#x2F; 设置inoutFormat，并设置按每两行读取</span><br><span class="line">        NLineInputFormat.setNumLinesPerSplit(job, 2);</span><br><span class="line">        job.setInputFormatClass(NLineInputFormat.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line">        job.setOutputKeyClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(&quot;F:\\Desktop\\hello.txt&quot;));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(&quot;F:\\Desktop\\output&quot;));</span><br><span class="line"></span><br><span class="line">        boolean b &#x3D; job.waitForCompletion(true);</span><br><span class="line"></span><br><span class="line">        System.exit( b ? 0 : 1);</span><br></pre></td></tr></table></figure>

<p>3、CombineTextInputFormat</p>
<p>mapper，reducer没啥区别，就是在Driver中设置下使用CombineInputFormat，如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 如果不设置InputFormat，它默认用的是TextInputFormat.class</span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;虚拟存储切片最大值设置4m</span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);</span><br></pre></td></tr></table></figure>



<h3 id="自定义InputFormat"><a href="#自定义InputFormat" class="headerlink" title="自定义InputFormat"></a>自定义InputFormat</h3><p>场景，现有一堆小文件，我们自己定义一个InputFormat，将这些小文件的数据读取称SequenceFile。key为文件路径+名称，value为文件内容。</p>
<p>首先，InputFormat中需要用到RecordReader对象，如果现有的Recorder对象不满足现有的需求，也需要定义RecorderReader。这里需要定义RecorderReader。</p>
<p>自定义的InputFormat不能将文件进行切片，一个文件内容就是一个小片。并且，用到的是自定义的RecorderReader。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">* 自定义的inputformat,将小文件读取成SequenceFile</span><br><span class="line"> * 路径加文件名为key，文件内容为value</span><br><span class="line"> *</span><br><span class="line"> * 继承FileInputFormat&lt;K,V&gt;,InputFormat的泛型类型，是作为Mapper的输入泛型类型的</span><br><span class="line"> *     K    Text，文件路径和名称</span><br><span class="line"> *     V    字节</span><br><span class="line"> *</span><br><span class="line"> *</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PathContentInputFormat</span> <span class="keyword">extends</span> <span class="title">FileInputFormat</span>&lt;<span class="title">Text</span>, <span class="title">BytesWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  文件不切片</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@author</span> GuoQiang.Zhou</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@date</span> 2020/1/3 22:44</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> filename</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">isSplitable</span><span class="params">(JobContext context, Path filename)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RecordReader&lt;Text, BytesWritable&gt; <span class="title">createRecordReader</span><span class="params">(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> PathContentRecordReader();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>自定义的RecorderReader如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"> *</span><br><span class="line"> * 自定义InputFormat的RecordReader，泛型和InputForamt保持一致</span><br><span class="line"> *</span><br><span class="line"> * 每个文件都会生成一个RecordReader</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class PathContentRecordReader extends RecordReader&lt;Text, BytesWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private Boolean notRead &#x3D; true;</span><br><span class="line"></span><br><span class="line">    private Text key &#x3D; new Text();</span><br><span class="line"></span><br><span class="line">    private BytesWritable value &#x3D; new BytesWritable();</span><br><span class="line"></span><br><span class="line">    private FSDataInputStream in;</span><br><span class="line"></span><br><span class="line">    private Path path;</span><br><span class="line">    private FileSplit fs;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     *  初始化RecordReader</span><br><span class="line">     * @author GuoQiang.Zhou</span><br><span class="line">     * @date 2020&#x2F;1&#x2F;3 22:38</span><br><span class="line">     * @param inputSplit</span><br><span class="line">     * @param context</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    @Override</span><br><span class="line">    public void initialize(InputSplit inputSplit, TaskAttemptContext context) throws IOException, InterruptedException &#123;</span><br><span class="line">        this.fs &#x3D; (FileSplit) inputSplit;</span><br><span class="line">        this.path &#x3D; this.fs.getPath();</span><br><span class="line"></span><br><span class="line">        FileSystem fileSystem &#x3D; path.getFileSystem(context.getConfiguration());</span><br><span class="line">        this.in &#x3D; fileSystem.open(path);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 是否有下一对kV</span><br><span class="line">     * @author GuoQiang.Zhou</span><br><span class="line">     * @date 2020&#x2F;1&#x2F;3 22:38</span><br><span class="line">     * @param</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    @Override</span><br><span class="line">    public boolean nextKeyValue() throws IOException, InterruptedException &#123;</span><br><span class="line">        if (this.notRead) &#123;</span><br><span class="line"></span><br><span class="line">            key.set(this.path.toString());</span><br><span class="line"></span><br><span class="line">            byte[] bytes &#x3D; new byte[(int) this.fs.getLength()];</span><br><span class="line"></span><br><span class="line">            in.read(bytes);</span><br><span class="line">            value.set(bytes,0, bytes.length);</span><br><span class="line"></span><br><span class="line">            this.notRead &#x3D; false;</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Text getCurrentKey() throws IOException, InterruptedException &#123;</span><br><span class="line">        return this.key;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public BytesWritable getCurrentValue() throws IOException, InterruptedException &#123;</span><br><span class="line">        return this.value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     *  读取的进度 ，百分比</span><br><span class="line">     * @author GuoQiang.Zhou</span><br><span class="line">     * @date 2020&#x2F;1&#x2F;3 22:38</span><br><span class="line">     * @param</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    @Override</span><br><span class="line">    public float getProgress() throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        return this.notRead ? 0 : 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     *  关闭</span><br><span class="line">     * @author GuoQiang.Zhou</span><br><span class="line">     * @date 2020&#x2F;1&#x2F;3 22:39</span><br><span class="line">     * @param</span><br><span class="line">     * @return</span><br><span class="line">     *&#x2F;</span><br><span class="line">    @Override</span><br><span class="line">        public void close() throws IOException &#123;</span><br><span class="line">        IOUtils.closeStream(this.in);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="自定义分区"><a href="#自定义分区" class="headerlink" title="自定义分区"></a>自定义分区</h3><p>这里的分区和shuffle中的分区不是同一个概念，shuffle中的分区是在mapTask有几种类型的key，按照字典序排序key，就会在逻辑上产生几个分区。这里的分区是reducerTask处理数据时的分区，他和reducerTask的数量相关。例如：某个需求是把reducerTask输出结果中按照key分类，输出到不同的文件中。如果默认不设置reducerTask，只会启动一个reducerTaask，所以只会有一个输出文件。所以，这时候就需要设置reducerTask的数量了。如果不自定义获取分区的，默认是按照key的hash值对reducerTask取模来确定分区号。自定义获取分区如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public class CustomPartition extends Partitioner&lt;Text, Text&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int getPartition(Text text, Text intWritable, int i) &#123;</span><br><span class="line"></span><br><span class="line">        switch (text.toString().substring(0, 3)) &#123;</span><br><span class="line">            case &quot;137&quot;:</span><br><span class="line">                return 0;</span><br><span class="line">            case &quot;138&quot;:</span><br><span class="line">                return 1;</span><br><span class="line">            case &quot;139&quot;:</span><br><span class="line">                return 2;</span><br><span class="line">            default:</span><br><span class="line">                return 3;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Partitioner的泛型和Reducer的输入泛型保持一致。并且最好分区数等于reducerTask数量，分区数多了，找不到对应的reducerTask，reducerTask多了，浪费资源，分区也必须连续。</p>
<h3 id="WritableComparable排序"><a href="#WritableComparable排序" class="headerlink" title="WritableComparable排序"></a>WritableComparable排序</h3><h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><p>在整个MR中，排序分为以下几类</p>
<p>1、部分排序</p>
<p>shuffle过程中会对MapperTask的输出文件内部排序，保证每个文件内部是有序的</p>
<p>2、全排序</p>
<p>MapperTask的输出文件在进入Reducer之前会进行一次全排序，保证所有数据有序</p>
<p>3、辅助排序</p>
<p>在Reducer中，对key进行分组。应用场景：key是bean对象时，实现WritableComparator接口，自定义排序规则</p>
<p>MapTask和Reducertask默认都会按照key的字典序进行排序。有时候，默认按照key的字典序排序无法满足需求，就需要自定义排序规则了。例如，如果key是一个bean，不是基本类型，那你就必须自定义排序，按照自己的要求对key排序</p>
<p>自定义排序规则如下，以key为bean为例，只需要实现WritableComparable接口，类似于Java中的Comparable接口。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public int compareTo(FlowBean o) &#123;</span><br><span class="line"></span><br><span class="line">	int result;</span><br><span class="line">		</span><br><span class="line">	&#x2F;&#x2F; 按照总流量大小，倒序排列</span><br><span class="line">	if (sumFlow &gt; bean.getSumFlow()) &#123;</span><br><span class="line">		result &#x3D; -1;</span><br><span class="line">	&#125;else if (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">		result &#x3D; 1;</span><br><span class="line">	&#125;else &#123;</span><br><span class="line">		result &#x3D; 0;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Combine合并"><a href="#Combine合并" class="headerlink" title="Combine合并"></a>Combine合并</h3><p>combiner是MR中Mapper和Reducer之外的组件，但其父类也是Reducer,本质上还是一个Reducer，他们之间的区别在于运行的位置。Reducer是接收全局所有Mapper的输出结果，combiner是在每一个MapperTask所在节点运行，处理所在节点的MapperTask的输出结果。Combiner的意义是对每一个MapperTask的输出进行局部汇总，减少网络IO。但是在某些情况下，combiner会影响到业务输出的结果，则就不能使用combiner了。</p>
<p>Combiner的定义和Reducer没有区别，使用的时候只要设置job的combiner类</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordcountCombiner.class);</span><br></pre></td></tr></table></figure>

<h3 id="GroupingComparator分组-辅助分组"><a href="#GroupingComparator分组-辅助分组" class="headerlink" title="GroupingComparator分组(辅助分组)"></a>GroupingComparator分组(辅助分组)</h3><p>GroupingComparator分组是也是针对key是bean的情况下1的，对Reducer阶段的数据根据某一个字段或者几个字段分组。类似于Java中自己顶一个比较器。</p>
<p>场景：在一堆订单数据中，按照订单编号排序，同一订单内数据，按照商品价格排序</p>
<p>首先需要定义一个Comparator类，继承WritableComparator类，构造器是必须的，传入需要排序的bean class类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CusGroupComparator</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">CusGroupComparator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(OrderComp<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        OrderComp o1 = (OrderComp) a;</span><br><span class="line">        OrderComp o2 = (OrderComp) b;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (o1.getOrderId() &gt; o2.getOrderId()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (o1.getOrderId() &lt; o2.getOrderId()) &#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一个要注意的地方就是，在订单id相同的某一篇数据里面，排序规则在OrderComp的comparato方法里已经定义好了，订单id升序，价格降序，自定义的Comparator类起到的作用是在Reducer汇总数据的时候，按照定义的规则分组。</p>
<h3 id="OutputFormat"><a href="#OutputFormat" class="headerlink" title="OutputFormat"></a>OutputFormat</h3><p>前面有讲到InputFormat，是用于读入数据时，按照规则读取数据。OutputFormat则是用于输出文件时，按照规则输出。</p>
<p>几种常见的OutputFormat如下：</p>
<p>1、TextOutputFormat：把每条记录写在一行</p>
<p>2、SequenceOutputFormat：将结果写在SequenceFileOutputFormat中，作为后续MR任务的输入，这种输出方式其内容格式紧凑，易于压缩</p>
<p>3、自定义</p>
<p>自定义OutputFormat：</p>
<p>​    -&gt; 现有场景:有一个服务调用接口的日文文件，将制定服务调用记录输出到一个文件，其他输入另一个文件</p>
<p>自定义OutputFormat</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public class CusOutputFormat extends FileOutputFormat&lt;Text, IntWritable&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public RecordWriter&lt;Text, IntWritable&gt; getRecordWriter(TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123;</span><br><span class="line">        return new CusRecordWriter(taskAttemptContext);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>自定义RecorderReader</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">public class CusRecordWriter extends RecordWriter&lt;Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private FSDataOutputStream particularOut &#x3D; null;</span><br><span class="line">    private FSDataOutputStream otherOut &#x3D; null;</span><br><span class="line"></span><br><span class="line">    public CusRecordWriter(TaskAttemptContext job) &#123;</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            FileSystem fs &#x3D; FileSystem.get(job.getConfiguration());</span><br><span class="line">            this.particularOut &#x3D; fs.create(new Path(&quot;F:\\Desktop\\reduceOut\\outputformat\\uc-user.log&quot;));</span><br><span class="line">            this.otherOut &#x3D; fs.create(new Path(&quot;F:\\Desktop\\reduceOut\\outputformat\\other.log&quot;));</span><br><span class="line"></span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void write(Text text, IntWritable intWritable) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        if (text.toString().contains(&quot;uc-user&quot;)) &#123;</span><br><span class="line">            particularOut.write(text.toString().getBytes());</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            otherOut.write(text.toString().getBytes());</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void close(TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        IOUtils.closeStream(this.particularOut);</span><br><span class="line">        IOUtils.closeStream(this.otherOut);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>设置使用自定义RecordWriter</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setOutputFormatClass(CusOutputFormat.class);</span><br></pre></td></tr></table></figure>

<h3 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h3><p>Join类似于sql中的join，将不同的数据按照某一个相同的字段拼起来。join可以在mapper里做，也可以在reducer里面做</p>
<h4 id="Reduce-join"><a href="#Reduce-join" class="headerlink" title="Reduce join"></a>Reduce join</h4><p>在reduce join 中，mapper主要将来自不同地方的数据，打上标志，标记来自于哪个地方。reducer中根据标记处理好数据</p>
<p>场景：现有2个文件，一个是订单信息，一个是商品信息，订单信息中只保存了订单编号，需要将商品信息填充到订单信息中。</p>
<p>join没有什么特殊的新知识点，都是逻辑的处理，示例如下</p>
<p>mapper</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">public class JoinMapper extends Mapper&lt;LongWritable, Text, Text, OrderProductInfo&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private String name;</span><br><span class="line">    private OrderProductInfo value &#x3D; new OrderProductInfo();</span><br><span class="line">    private Text key &#x3D; new Text();</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * mappertask 每次启动时，会调用一次</span><br><span class="line">     *</span><br><span class="line">     * @param context</span><br><span class="line">     * @return</span><br><span class="line">     * @author GuoQiang.Zhou</span><br><span class="line">     * @date 2020&#x2F;1&#x2F;11 17:54</span><br><span class="line">     *&#x2F;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void setup(Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 获取处理的当前文件切片</span><br><span class="line">        FileSplit inputSplit &#x3D; (FileSplit) context.getInputSplit();</span><br><span class="line">        this.name &#x3D; inputSplit.getPath().getName();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        String line &#x3D; value.toString();</span><br><span class="line"></span><br><span class="line">        String[] split &#x3D; line.split(&quot;\t&quot;);</span><br><span class="line">        if (this.name.equals(&quot;order.txt&quot;)) &#123;</span><br><span class="line">            this.value.setOrderId(split[0]);</span><br><span class="line">            this.value.setPId(split[1]);</span><br><span class="line">            this.value.setAmount(Integer.parseInt(split[2]));</span><br><span class="line">            this.value.setPname(&quot;&quot;);</span><br><span class="line">            this.value.setFlag(&quot;order&quot;);</span><br><span class="line">            this.key.set(split[1]);</span><br><span class="line"></span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            this.value.setOrderId(&quot;&quot;);</span><br><span class="line">            this.value.setPId(split[0]);</span><br><span class="line">            this.value.setAmount(0);</span><br><span class="line">            this.value.setPname(split[1]);</span><br><span class="line">            this.value.setFlag(&quot;pd&quot;);</span><br><span class="line">            this.key.set(split[0]);</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(this.key, this.value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>reducer</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class JoinReducer extends Reducer&lt;Text, OrderProductInfo, OrderProductInfo, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    protected void reduce(Text key, Iterable&lt;OrderProductInfo&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        Iterator&lt;OrderProductInfo&gt; iterator &#x3D; values.iterator();</span><br><span class="line">        String pName &#x3D; iterator.next().getPname();</span><br><span class="line">        while (iterator.hasNext()) &#123;</span><br><span class="line">            OrderProductInfo next &#x3D; iterator.next();</span><br><span class="line">            next.setPname(pName);</span><br><span class="line">            context.write(next, NullWritable.get());</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，reducer join中合并的操作是在reducer中进行的。数据量大的话，reducer压力会很大</p>
<h4 id="map-join"><a href="#map-join" class="headerlink" title="map join"></a>map join</h4><p>mapper join是将合并的操作放在mapper阶段，减轻reducer压力。在mapper端做，需要将部分数据设置到缓存文件，在mapper的setUp中，回去加载这个缓存文件。由此可见，设置的缓存文件不应很大，否则，单读取缓存文件的开销就很大</p>
<p>同样的案例，在mapper中做不同点在于setup的加载文件，其他一样</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapJoinMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">OrderProductInfo</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> OrderProductInfo value = <span class="keyword">new</span> OrderProductInfo();</span><br><span class="line">    <span class="keyword">private</span> Text key = <span class="keyword">new</span> Text();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        URI[] files = context.getCacheFiles();</span><br><span class="line">        String path = files[<span class="number">0</span>].getPath();</span><br><span class="line">        BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(<span class="keyword">new</span> FileInputStream(path)));</span><br><span class="line">        String line;</span><br><span class="line">        <span class="keyword">while</span> (StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line">            String[] split = line.split(<span class="string">"\t"</span>);</span><br><span class="line">            <span class="keyword">this</span>.map.put(split[<span class="number">0</span>], split[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        IOUtils.closeStream(reader);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        String line = value.toString();</span><br><span class="line"></span><br><span class="line">        String[] split = line.split(<span class="string">"\t"</span>);</span><br><span class="line">        <span class="keyword">this</span>.value.setOrderId(split[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">this</span>.value.setPId(<span class="string">""</span>);</span><br><span class="line">        <span class="keyword">this</span>.value.setAmount(Integer.parseInt(split[<span class="number">2</span>]));</span><br><span class="line">        <span class="keyword">this</span>.value.setPname(<span class="keyword">this</span>.map.get(split[<span class="number">1</span>]));</span><br><span class="line">        <span class="keyword">this</span>.key.set(split[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        context.write(<span class="keyword">this</span>.key, <span class="keyword">this</span>.value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>简单来说，数据清洗就是在处理前，对数据过滤一遍，去掉无用的数据</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>从mapReduce处理数据的流程原理图上面可以看到在mapReduce中数据的流向。</p>
<p>按我自己的看法先来拆分下job从提交到输出的整个过程。</p>
<p>提交job阶段</p>
<p>1、首先客户端在submit之前，获取到要处理的信息，根据参数的配置，形成一个任务分配的规划。假设这个job要处理的数据有300M，块大小假设默认，那么这个文件在hdfs上就是被分为三块的，分别存在三个节点上。客户端根据此计算出，该任务切分为3份，然后提交job。Yarn根据此job的切分，计算要启动3个MapTask，分别处理三个节点上的数据。</p>
<p>2、InputFormat读取数据：</p>
<p>在每个</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">zgq</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://avajbuhtig.github.io/2020/01/01/hadoop%E4%B9%8BmapReduce/">https://avajbuhtig.github.io/2020/01/01/hadoop%E4%B9%8BmapReduce/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://avajbuhtig.github.io" target="_blank">zgq's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE-hadoop-MapReduce/">大数据  hadoop MapReduce</a></div><div class="post_share"><div class="social-share" data-image="/img/post.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/01/22/zookeeper/"><img class="prev_cover lazyload" data-src="/img/post.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">zookeeper基础</div></div></a></div><div class="next-post pull_right"><a href="/2020/01/01/hadoop%E4%B9%8B%E5%9F%BA%E7%A1%80%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"><img class="next_cover lazyload" data-src="/img/post.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">hadoop之基础集群搭建</div></div></a></div></nav></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By zgq</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>